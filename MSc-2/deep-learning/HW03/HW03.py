# -*- coding: utf-8 -*-
"""HW03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16rcyO1XAqsDI4NTJJPm63smWjtc_YnY3
"""

!pip install comet_ml --quiet

import comet_ml
comet_ml.login()

import numpy as np
import matplotlib.pyplot as plt
import cv2
from scipy import io
from tensorflow.keras.models import Sequential
from tensorflow.keras.constraints import MaxNorm
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import regularizers

def build_model_graph(experiment):
    model = Sequential()
    model.add(Dense(experiment.get_parameter("first_layer_units"),
                    input_shape=(400,),
                    activation='relu',
                    kernel_constraint=MaxNorm(3),
                    kernel_regularizer=experiment.get_parameter("k_r")))
    model.add(Dropout(0.2))
    model.add(Dense(200, activation='relu',
                    kernel_constraint=MaxNorm(3),
                    kernel_regularizer=experiment.get_parameter("k_r")))
    model.add(Dropout(0.2))
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    return model

def train(experiment, model, X_tr, Y_tr):
    history = model.fit(X_tr, Y_tr,
                        batch_size=experiment.get_parameter("batch_size"),
                        epochs=experiment.get_parameter("epochs"),
                        validation_split=0.2)
    experiment.log_metric("loss", history.history['loss'][-1])
    experiment.log_metric("val_loss", history.history['val_loss'][-1])
    return history

def evaluate(experiment, model, X_te, Y_te):
    score = model.evaluate(X_te, Y_te, verbose=0)
    experiment.log_metric("test_loss", score[0])
    experiment.log_metric("test_accuracy", score[1])
    print("Test Loss:", score[0])
    print("Test Accuracy:", score[1])
    return score

def get_dataset():
    dataset = io.loadmat('/content/Data_hoda_full.mat')
    x_tr = np.squeeze(dataset['Data'][:10000])
    y_tr = np.squeeze(dataset['labels'][:10000])
    x_te = np.squeeze(dataset['Data'][10000:12000])
    y_te = np.squeeze(dataset['labels'][10000:12000])
    width, height = 20, 20
    X_tr = np.zeros((x_tr.shape[0], width*height))
    X_te = np.zeros((x_te.shape[0], width*height))
    for i, img in enumerate(x_tr):
        X_tr[i] = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST).ravel()/255
    for i, img in enumerate(x_te):
        X_te[i] = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST).ravel()/255
    Y_tr = to_categorical(y_tr, 10)
    Y_te = to_categorical(y_te, 10)
    return X_tr, Y_tr, X_te, Y_te, x_tr

X_tr, Y_tr, X_te, Y_te, raw_tr = get_dataset()

plt.figure(figsize=(3,3))
for i in range(6):
    plt.subplot(2,3,i+1)
    plt.xticks([]); plt.yticks([]); plt.grid(False)
    plt.imshow(raw_tr[i], cmap='binary')
plt.show()

config = {
    "algorithm": "bayes",
    "name": "Optimize My Network",
    "spec": {"maxCombo": 5, "objective": "minimize", "metric": "loss"},
    "parameters": {
        "first_layer_units": {"type": "integer", "mu": 500, "sigma": 50, "scalingType": "normal"},
        "batch_size": {"type": "discrete", "values": [64, 128, 256]},
        "k_r": {"type": "categorical", "values": ["l1", "l2"]},
    },
    "trials": 2,
}

opt = comet_ml.Optimizer(config)

best_acc = 0
best_params = None

for experiment in opt.get_experiments():
    experiment.log_parameter("epochs", 50)
    model = build_model_graph(experiment)
    history = train(experiment, model, X_tr, Y_tr)
    score = evaluate(experiment, model, X_te, Y_te)
    trial_params = {
        "first_layer_units": experiment.get_parameter("first_layer_units"),
        "batch_size": experiment.get_parameter("batch_size"),
        "k_r": experiment.get_parameter("k_r"),
        "epochs": experiment.get_parameter("epochs")
    }
    if score[1] > best_acc:
        best_acc = score[1]
        best_params = trial_params
    plt.plot(history.history['loss'], label='Train Loss', color='red')
    plt.plot(history.history['val_loss'], label='Validation Loss', color='blue')
    plt.legend(); plt.show()
    plt.plot(history.history['accuracy'], label='Train Accuracy', color='red')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue')
    plt.legend(); plt.show()
    preds = model.predict(X_te[:5])
    for i in range(5):
        plt.imshow(X_te[i].reshape(20,20), cmap='binary')
        plt.title(f"True: {np.argmax(Y_te[i])}, Pred: {np.argmax(preds[i])}")
        plt.show()
    experiment.end()

print("Best Test Accuracy:", best_acc)
print("Best Parameters:", best_params)